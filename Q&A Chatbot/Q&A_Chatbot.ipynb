{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q&A Chatbot.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcuGYF71oxOthguQe2lzu1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VigneshwaraChinnadurai/DL_Works/blob/master/Q%26A%20Chatbot/Q%26A_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EcINn6FN8XT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R1Qri53PG7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d792490-aa93-4817-9766-0f2e22b0c085"
      },
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIPI5uZRPWe3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80e05321-f28e-4fef-c52b-9f2645c1d69f"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysvt-v-8QDEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IZywy2oPX1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#STEP-1: Install Import Libraries\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#STEP-2: Autheticate E-Mail ID\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#STEP-3: Get File from Drive using file-ID\n",
        "\n",
        "#2.1 Get the file\n",
        "downloaded = drive.CreateFile({'id':'12TsfynouQ3E2vagWGVJ2u-Vs-Qav-5Te'})\n",
        "# replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('test_qa.txt') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PQpaIbrP5GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At3AaXR4P9In",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#STEP-1: Install Import Libraries\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#STEP-2: Autheticate E-Mail ID\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#STEP-3: Get File from Drive using file-ID\n",
        "\n",
        "#2.1 Get the file\n",
        "downloaded = drive.CreateFile({'id':'1c4pw-dW9wYLNzY5YbS3NtQebIKm04FHp'})\n",
        "# replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('train_qa.txt') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o7rlypJQZPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2ZMKqG5QpEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3170816c-c9aa-43cf-e0ad-09ceba660d43"
      },
      "source": [
        "type(test_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjLT8X-cQuxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbc34419-fbdc-4f19-f85c-13c72530e6dc"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFHn8npFQx-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b3d4ce9-52f2-4a11-d596-2622a1fbcdb6"
      },
      "source": [
        "type(train_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtWrYGkTQzQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f04c0967-8c78-496b-fd54-197d45414628"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daMb-EHrQ0iX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "d79fba55-9411-4a95-b35a-9908178a315d"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuWM8-__Q3Ou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e132059-a6c0-44ad-9d8a-9e384d8f9f4c"
      },
      "source": [
        "' '.join(train_data[0][0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3ht3WelQ74U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note the training dataset has space inbetween the period and last word of each sentence\n",
        "# Similarly for every other punctuation."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2_rj0IFRI8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b18e7ed-0414-4524-ed0b-6c60e49ce9d1"
      },
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is Sandra in the hallway ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s21A9gY1RQdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a set that holds the vocab words\n",
        "vocab = set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzpIbGsTRSFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = test_data + train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7IAOW5ORTQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for story, question , answer in all_data:\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WsrSta9RXUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53aiyVLCRYkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "a06ada64-bc11-4e58-db4b-c35e02a736f0"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vwfhJHQRaK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a small vocabulary set by which we're unfortunately forced to select words from it. (Sorry for that. :( )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrEpJBlGRp_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APrVTtvSRt75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_story_len = max([len(data[0]) for data in all_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9hwOtPiRvLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "970db60b-2592-4eaf-eba8-547f61efedda"
      },
      "source": [
        "max_story_len"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNUPWkqSRwYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_question_len = max([len(data[1]) for data in all_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5u2UTKjRxoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80e9a113-cb88-47d6-b277-0b7392c84447"
      },
      "source": [
        "max_question_len"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3TT4F1ARzWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reserve 0 for pad_sequences\n",
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDBU-TvqR3jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceb243c2-bb70-442e-c8e9-df1af6785be7"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVGdiG25R5ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1aXlnaAR7S8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "2e29fe50-f215-46dc-e281-15b3bcf2ff66"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 32,\n",
              " '?': 23,\n",
              " 'apple': 31,\n",
              " 'back': 30,\n",
              " 'bathroom': 8,\n",
              " 'bedroom': 15,\n",
              " 'daniel': 22,\n",
              " 'discarded': 13,\n",
              " 'down': 2,\n",
              " 'dropped': 9,\n",
              " 'football': 6,\n",
              " 'garden': 21,\n",
              " 'got': 36,\n",
              " 'grabbed': 25,\n",
              " 'hallway': 33,\n",
              " 'in': 20,\n",
              " 'is': 12,\n",
              " 'john': 14,\n",
              " 'journeyed': 17,\n",
              " 'kitchen': 10,\n",
              " 'left': 3,\n",
              " 'mary': 18,\n",
              " 'milk': 5,\n",
              " 'moved': 11,\n",
              " 'no': 27,\n",
              " 'office': 16,\n",
              " 'picked': 29,\n",
              " 'put': 19,\n",
              " 'sandra': 24,\n",
              " 'the': 28,\n",
              " 'there': 1,\n",
              " 'to': 34,\n",
              " 'took': 37,\n",
              " 'travelled': 35,\n",
              " 'up': 4,\n",
              " 'went': 7,\n",
              " 'yes': 26}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoPKXW4iR80F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHlKZs8aR-vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwpspHNTR_-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58805503-5e47-4b05-9a51-f0ca7cde3e9a"
      },
      "source": [
        "len(train_story_text)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8PICGbBSBCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "    # For this problem\n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "    \n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        \n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "        \n",
        "    # RETURN TUPLE FOR UNPACKING\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eueo3g_pSri4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-bYmkKISsl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM-OQNVMStsB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "7c7ec063-9e22-4df7-d3c2-90905fde3bc5"
      },
      "source": [
        "inputs_test"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 28, 15, 32],\n",
              "       [ 0,  0,  0, ..., 28, 21, 32],\n",
              "       [ 0,  0,  0, ..., 28, 21, 32],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 28, 31, 32],\n",
              "       [ 0,  0,  0, ..., 28, 21, 32],\n",
              "       [ 0,  0,  0, ..., 31,  1, 32]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq8TbzpqS05d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "3c634133-dd27-4cec-ae8d-da8d6a4c05f3"
      },
      "source": [
        "queries_test"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12, 14, 20, 28, 10, 23],\n",
              "       [12, 14, 20, 28, 10, 23],\n",
              "       [12, 14, 20, 28, 21, 23],\n",
              "       ...,\n",
              "       [12, 18, 20, 28, 15, 23],\n",
              "       [12, 24, 20, 28, 21, 23],\n",
              "       [12, 18, 20, 28, 21, 23]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHza0-aMS2Bd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "78e127ce-69b7-407a-ddb3-535f4335e9cc"
      },
      "source": [
        "answers_test"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mukioscHS3Ry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4702fd61-8139-422e-c6d5-7563e7940747"
      },
      "source": [
        "sum(answers_test)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0., 497., 503.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKPyLv9YS4di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We have count for only 2 columns which are YES and NO."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1AHdJxcTCnL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c89becd9-4140-4b11-cf36-3b84aa7b029b"
      },
      "source": [
        "tokenizer.word_index['yes']"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aNL_9ZQTEMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5011412-86f4-4742-d521-23bca64f85b3"
      },
      "source": [
        "tokenizer.word_index['no']"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM88SMe4TFOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating model\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMkknDDeTLBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating placeholders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjpS8sfOTQqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjzyLYB5TQ4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input Encoder M\n",
        "\n",
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# Output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9FriIGXTXwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input Encoder C\n",
        "\n",
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg7v3YlbTjSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question Encoder\n",
        "\n",
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG4X97usTnIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoding the sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGPkObIgTrCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RmPBH_-TrtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using dot product to compute the match between first i/p vector sequence and the query\n",
        "\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75frChueUMri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding this match matrix with the second input vector sequence\n",
        "\n",
        "response = add([match, input_encoded_c])  \n",
        "response = Permute((2, 1))(response) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnW02hpZUV7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmPBg8piUZpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_LoLvmvUhHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzXg9MKZUlki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we're outputing a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# building the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqVhyiduUvO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "3e34cc57-e5a6-4d4e-c7c0-ad0cee0b14de"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 156)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       multiple             2432        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 156, 6)       0           sequential_2[1][0]               \n",
            "                                                                 sequential_4[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       multiple             228         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
            "                                                                 sequential_4[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 38)           1254        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKSYRq5BUx5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17b4ba13-82e8-4c44-9659-3e04729b8ee8"
      },
      "source": [
        "# Let's do it\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/120\n",
            "10000/10000 [==============================] - 8s 775us/step - loss: 0.8675 - accuracy: 0.4980 - val_loss: 0.6960 - val_accuracy: 0.5030\n",
            "Epoch 2/120\n",
            "10000/10000 [==============================] - 6s 570us/step - loss: 0.7012 - accuracy: 0.4999 - val_loss: 0.6943 - val_accuracy: 0.5030\n",
            "Epoch 3/120\n",
            "10000/10000 [==============================] - 6s 572us/step - loss: 0.6959 - accuracy: 0.4981 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
            "Epoch 4/120\n",
            "10000/10000 [==============================] - 6s 567us/step - loss: 0.6951 - accuracy: 0.5050 - val_loss: 0.6973 - val_accuracy: 0.4970\n",
            "Epoch 5/120\n",
            "10000/10000 [==============================] - 6s 577us/step - loss: 0.6945 - accuracy: 0.4997 - val_loss: 0.6954 - val_accuracy: 0.4970\n",
            "Epoch 6/120\n",
            "10000/10000 [==============================] - 6s 563us/step - loss: 0.6944 - accuracy: 0.5070 - val_loss: 0.6962 - val_accuracy: 0.5030\n",
            "Epoch 7/120\n",
            "10000/10000 [==============================] - 5s 544us/step - loss: 0.6947 - accuracy: 0.4971 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
            "Epoch 8/120\n",
            "10000/10000 [==============================] - 6s 574us/step - loss: 0.6943 - accuracy: 0.5020 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
            "Epoch 9/120\n",
            "10000/10000 [==============================] - 5s 550us/step - loss: 0.6939 - accuracy: 0.5089 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
            "Epoch 10/120\n",
            "10000/10000 [==============================] - 5s 543us/step - loss: 0.6946 - accuracy: 0.5041 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
            "Epoch 11/120\n",
            "10000/10000 [==============================] - 5s 543us/step - loss: 0.6943 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 12/120\n",
            "10000/10000 [==============================] - 6s 584us/step - loss: 0.6939 - accuracy: 0.5046 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 13/120\n",
            "10000/10000 [==============================] - 6s 557us/step - loss: 0.6938 - accuracy: 0.5056 - val_loss: 0.6939 - val_accuracy: 0.4950\n",
            "Epoch 14/120\n",
            "10000/10000 [==============================] - 6s 587us/step - loss: 0.6934 - accuracy: 0.5120 - val_loss: 0.6945 - val_accuracy: 0.4850\n",
            "Epoch 15/120\n",
            "10000/10000 [==============================] - 6s 555us/step - loss: 0.6878 - accuracy: 0.5362 - val_loss: 0.6828 - val_accuracy: 0.5380\n",
            "Epoch 16/120\n",
            "10000/10000 [==============================] - 6s 610us/step - loss: 0.6509 - accuracy: 0.6278 - val_loss: 0.6250 - val_accuracy: 0.6560\n",
            "Epoch 17/120\n",
            "10000/10000 [==============================] - 5s 549us/step - loss: 0.6219 - accuracy: 0.6584 - val_loss: 0.5942 - val_accuracy: 0.6920\n",
            "Epoch 18/120\n",
            "10000/10000 [==============================] - 6s 604us/step - loss: 0.5905 - accuracy: 0.6917 - val_loss: 0.5646 - val_accuracy: 0.7260\n",
            "Epoch 19/120\n",
            "10000/10000 [==============================] - 6s 573us/step - loss: 0.5529 - accuracy: 0.7303 - val_loss: 0.5098 - val_accuracy: 0.7590\n",
            "Epoch 20/120\n",
            "10000/10000 [==============================] - 6s 556us/step - loss: 0.5147 - accuracy: 0.7582 - val_loss: 0.5211 - val_accuracy: 0.7540\n",
            "Epoch 21/120\n",
            "10000/10000 [==============================] - 5s 549us/step - loss: 0.4898 - accuracy: 0.7773 - val_loss: 0.4528 - val_accuracy: 0.8110\n",
            "Epoch 22/120\n",
            "10000/10000 [==============================] - 5s 529us/step - loss: 0.4686 - accuracy: 0.7919 - val_loss: 0.4355 - val_accuracy: 0.8060\n",
            "Epoch 23/120\n",
            "10000/10000 [==============================] - 6s 604us/step - loss: 0.4395 - accuracy: 0.8102 - val_loss: 0.4519 - val_accuracy: 0.8130\n",
            "Epoch 24/120\n",
            "10000/10000 [==============================] - 5s 537us/step - loss: 0.4227 - accuracy: 0.8206 - val_loss: 0.5260 - val_accuracy: 0.7740\n",
            "Epoch 25/120\n",
            "10000/10000 [==============================] - 6s 576us/step - loss: 0.4156 - accuracy: 0.8216 - val_loss: 0.4298 - val_accuracy: 0.7930\n",
            "Epoch 26/120\n",
            "10000/10000 [==============================] - 6s 553us/step - loss: 0.3974 - accuracy: 0.8312 - val_loss: 0.4458 - val_accuracy: 0.8170\n",
            "Epoch 27/120\n",
            "10000/10000 [==============================] - 6s 552us/step - loss: 0.3921 - accuracy: 0.8336 - val_loss: 0.4104 - val_accuracy: 0.8050\n",
            "Epoch 28/120\n",
            "10000/10000 [==============================] - 5s 549us/step - loss: 0.3813 - accuracy: 0.8391 - val_loss: 0.3826 - val_accuracy: 0.8360\n",
            "Epoch 29/120\n",
            "10000/10000 [==============================] - 6s 587us/step - loss: 0.3762 - accuracy: 0.8394 - val_loss: 0.4200 - val_accuracy: 0.8180\n",
            "Epoch 30/120\n",
            "10000/10000 [==============================] - 6s 599us/step - loss: 0.3667 - accuracy: 0.8469 - val_loss: 0.4071 - val_accuracy: 0.8070\n",
            "Epoch 31/120\n",
            "10000/10000 [==============================] - 6s 566us/step - loss: 0.3660 - accuracy: 0.8446 - val_loss: 0.3831 - val_accuracy: 0.8370\n",
            "Epoch 32/120\n",
            "10000/10000 [==============================] - 6s 594us/step - loss: 0.3626 - accuracy: 0.8454 - val_loss: 0.3845 - val_accuracy: 0.8270\n",
            "Epoch 33/120\n",
            "10000/10000 [==============================] - 5s 547us/step - loss: 0.3634 - accuracy: 0.8462 - val_loss: 0.3873 - val_accuracy: 0.8300\n",
            "Epoch 34/120\n",
            "10000/10000 [==============================] - 6s 576us/step - loss: 0.3494 - accuracy: 0.8540 - val_loss: 0.3809 - val_accuracy: 0.8210\n",
            "Epoch 35/120\n",
            "10000/10000 [==============================] - 6s 555us/step - loss: 0.3487 - accuracy: 0.8513 - val_loss: 0.3717 - val_accuracy: 0.8340\n",
            "Epoch 36/120\n",
            "10000/10000 [==============================] - 6s 586us/step - loss: 0.3427 - accuracy: 0.8520 - val_loss: 0.3767 - val_accuracy: 0.8380\n",
            "Epoch 37/120\n",
            "10000/10000 [==============================] - 6s 603us/step - loss: 0.3427 - accuracy: 0.8542 - val_loss: 0.4060 - val_accuracy: 0.8070\n",
            "Epoch 38/120\n",
            "10000/10000 [==============================] - 6s 553us/step - loss: 0.3395 - accuracy: 0.8534 - val_loss: 0.3744 - val_accuracy: 0.8330\n",
            "Epoch 39/120\n",
            "10000/10000 [==============================] - 6s 601us/step - loss: 0.3353 - accuracy: 0.8564 - val_loss: 0.3772 - val_accuracy: 0.8370\n",
            "Epoch 40/120\n",
            "10000/10000 [==============================] - 6s 590us/step - loss: 0.3377 - accuracy: 0.8534 - val_loss: 0.3704 - val_accuracy: 0.8320\n",
            "Epoch 41/120\n",
            "10000/10000 [==============================] - 6s 585us/step - loss: 0.3302 - accuracy: 0.8586 - val_loss: 0.4029 - val_accuracy: 0.8260\n",
            "Epoch 42/120\n",
            "10000/10000 [==============================] - 6s 564us/step - loss: 0.3313 - accuracy: 0.8583 - val_loss: 0.3964 - val_accuracy: 0.8280\n",
            "Epoch 43/120\n",
            "10000/10000 [==============================] - 6s 569us/step - loss: 0.3275 - accuracy: 0.8605 - val_loss: 0.3840 - val_accuracy: 0.8310\n",
            "Epoch 44/120\n",
            "10000/10000 [==============================] - 6s 567us/step - loss: 0.3287 - accuracy: 0.8570 - val_loss: 0.3718 - val_accuracy: 0.8360\n",
            "Epoch 45/120\n",
            "10000/10000 [==============================] - 5s 543us/step - loss: 0.3216 - accuracy: 0.8623 - val_loss: 0.3728 - val_accuracy: 0.8440\n",
            "Epoch 46/120\n",
            "10000/10000 [==============================] - 6s 564us/step - loss: 0.3223 - accuracy: 0.8608 - val_loss: 0.3788 - val_accuracy: 0.8170\n",
            "Epoch 47/120\n",
            "10000/10000 [==============================] - 6s 553us/step - loss: 0.3189 - accuracy: 0.8645 - val_loss: 0.3620 - val_accuracy: 0.8370\n",
            "Epoch 48/120\n",
            "10000/10000 [==============================] - 5s 539us/step - loss: 0.3170 - accuracy: 0.8633 - val_loss: 0.3703 - val_accuracy: 0.8400\n",
            "Epoch 49/120\n",
            "10000/10000 [==============================] - 5s 546us/step - loss: 0.3183 - accuracy: 0.8643 - val_loss: 0.3709 - val_accuracy: 0.8390\n",
            "Epoch 50/120\n",
            "10000/10000 [==============================] - 6s 583us/step - loss: 0.3136 - accuracy: 0.8631 - val_loss: 0.3615 - val_accuracy: 0.8420\n",
            "Epoch 51/120\n",
            "10000/10000 [==============================] - 6s 556us/step - loss: 0.3098 - accuracy: 0.8658 - val_loss: 0.3628 - val_accuracy: 0.8370\n",
            "Epoch 52/120\n",
            "10000/10000 [==============================] - 5s 544us/step - loss: 0.3091 - accuracy: 0.8657 - val_loss: 0.3585 - val_accuracy: 0.8430\n",
            "Epoch 53/120\n",
            "10000/10000 [==============================] - 5s 541us/step - loss: 0.3083 - accuracy: 0.8644 - val_loss: 0.3705 - val_accuracy: 0.8350\n",
            "Epoch 54/120\n",
            "10000/10000 [==============================] - 6s 580us/step - loss: 0.3063 - accuracy: 0.8691 - val_loss: 0.3646 - val_accuracy: 0.8340\n",
            "Epoch 55/120\n",
            "10000/10000 [==============================] - 6s 569us/step - loss: 0.3033 - accuracy: 0.8666 - val_loss: 0.3552 - val_accuracy: 0.8400\n",
            "Epoch 56/120\n",
            "10000/10000 [==============================] - 6s 554us/step - loss: 0.3066 - accuracy: 0.8683 - val_loss: 0.3620 - val_accuracy: 0.8430\n",
            "Epoch 57/120\n",
            "10000/10000 [==============================] - 6s 556us/step - loss: 0.3031 - accuracy: 0.8660 - val_loss: 0.3577 - val_accuracy: 0.8430\n",
            "Epoch 58/120\n",
            "10000/10000 [==============================] - 5s 540us/step - loss: 0.3030 - accuracy: 0.8671 - val_loss: 0.3695 - val_accuracy: 0.8390\n",
            "Epoch 59/120\n",
            "10000/10000 [==============================] - 6s 581us/step - loss: 0.3011 - accuracy: 0.8695 - val_loss: 0.3751 - val_accuracy: 0.8370\n",
            "Epoch 60/120\n",
            "10000/10000 [==============================] - 6s 587us/step - loss: 0.3001 - accuracy: 0.8701 - val_loss: 0.3697 - val_accuracy: 0.8420\n",
            "Epoch 61/120\n",
            "10000/10000 [==============================] - 6s 577us/step - loss: 0.3007 - accuracy: 0.8706 - val_loss: 0.3722 - val_accuracy: 0.8390\n",
            "Epoch 62/120\n",
            "10000/10000 [==============================] - 6s 596us/step - loss: 0.2934 - accuracy: 0.8701 - val_loss: 0.3609 - val_accuracy: 0.8380\n",
            "Epoch 63/120\n",
            "10000/10000 [==============================] - 6s 569us/step - loss: 0.2928 - accuracy: 0.8755 - val_loss: 0.3659 - val_accuracy: 0.8450\n",
            "Epoch 64/120\n",
            "10000/10000 [==============================] - 6s 570us/step - loss: 0.2881 - accuracy: 0.8775 - val_loss: 0.3651 - val_accuracy: 0.8430\n",
            "Epoch 65/120\n",
            "10000/10000 [==============================] - 6s 574us/step - loss: 0.2868 - accuracy: 0.8777 - val_loss: 0.3766 - val_accuracy: 0.8380\n",
            "Epoch 66/120\n",
            "10000/10000 [==============================] - 5s 549us/step - loss: 0.2866 - accuracy: 0.8746 - val_loss: 0.3836 - val_accuracy: 0.8430\n",
            "Epoch 67/120\n",
            "10000/10000 [==============================] - 5s 545us/step - loss: 0.2847 - accuracy: 0.8780 - val_loss: 0.3625 - val_accuracy: 0.8400\n",
            "Epoch 68/120\n",
            "10000/10000 [==============================] - 5s 548us/step - loss: 0.2873 - accuracy: 0.8774 - val_loss: 0.3793 - val_accuracy: 0.8300\n",
            "Epoch 69/120\n",
            "10000/10000 [==============================] - 6s 580us/step - loss: 0.2824 - accuracy: 0.8780 - val_loss: 0.3767 - val_accuracy: 0.8460\n",
            "Epoch 70/120\n",
            "10000/10000 [==============================] - 6s 565us/step - loss: 0.2766 - accuracy: 0.8844 - val_loss: 0.4002 - val_accuracy: 0.8350\n",
            "Epoch 71/120\n",
            "10000/10000 [==============================] - 6s 554us/step - loss: 0.2785 - accuracy: 0.8842 - val_loss: 0.3779 - val_accuracy: 0.8380\n",
            "Epoch 72/120\n",
            "10000/10000 [==============================] - 6s 570us/step - loss: 0.2793 - accuracy: 0.8808 - val_loss: 0.3790 - val_accuracy: 0.8410\n",
            "Epoch 73/120\n",
            "10000/10000 [==============================] - 6s 568us/step - loss: 0.2779 - accuracy: 0.8817 - val_loss: 0.3841 - val_accuracy: 0.8420\n",
            "Epoch 74/120\n",
            "10000/10000 [==============================] - 6s 551us/step - loss: 0.2786 - accuracy: 0.8796 - val_loss: 0.3735 - val_accuracy: 0.8460\n",
            "Epoch 75/120\n",
            "10000/10000 [==============================] - 6s 556us/step - loss: 0.2758 - accuracy: 0.8847 - val_loss: 0.3760 - val_accuracy: 0.8380\n",
            "Epoch 76/120\n",
            "10000/10000 [==============================] - 6s 569us/step - loss: 0.2735 - accuracy: 0.8834 - val_loss: 0.3864 - val_accuracy: 0.8400\n",
            "Epoch 77/120\n",
            "10000/10000 [==============================] - 6s 568us/step - loss: 0.2698 - accuracy: 0.8874 - val_loss: 0.3836 - val_accuracy: 0.8380\n",
            "Epoch 78/120\n",
            "10000/10000 [==============================] - 6s 560us/step - loss: 0.2712 - accuracy: 0.8870 - val_loss: 0.3766 - val_accuracy: 0.8360\n",
            "Epoch 79/120\n",
            "10000/10000 [==============================] - 6s 560us/step - loss: 0.2672 - accuracy: 0.8858 - val_loss: 0.3889 - val_accuracy: 0.8460\n",
            "Epoch 80/120\n",
            "10000/10000 [==============================] - 6s 582us/step - loss: 0.2622 - accuracy: 0.8876 - val_loss: 0.4079 - val_accuracy: 0.8320\n",
            "Epoch 81/120\n",
            "10000/10000 [==============================] - 6s 597us/step - loss: 0.2594 - accuracy: 0.8884 - val_loss: 0.4323 - val_accuracy: 0.8430\n",
            "Epoch 82/120\n",
            "10000/10000 [==============================] - 6s 577us/step - loss: 0.2614 - accuracy: 0.8861 - val_loss: 0.4068 - val_accuracy: 0.8440\n",
            "Epoch 83/120\n",
            "10000/10000 [==============================] - 5s 546us/step - loss: 0.2589 - accuracy: 0.8894 - val_loss: 0.4081 - val_accuracy: 0.8340\n",
            "Epoch 84/120\n",
            "10000/10000 [==============================] - 6s 588us/step - loss: 0.2597 - accuracy: 0.8875 - val_loss: 0.4146 - val_accuracy: 0.8400\n",
            "Epoch 85/120\n",
            "10000/10000 [==============================] - 6s 551us/step - loss: 0.2541 - accuracy: 0.8931 - val_loss: 0.4366 - val_accuracy: 0.8420\n",
            "Epoch 86/120\n",
            "10000/10000 [==============================] - 6s 605us/step - loss: 0.2516 - accuracy: 0.8925 - val_loss: 0.4440 - val_accuracy: 0.8370\n",
            "Epoch 87/120\n",
            "10000/10000 [==============================] - 6s 595us/step - loss: 0.2504 - accuracy: 0.8952 - val_loss: 0.4226 - val_accuracy: 0.8400\n",
            "Epoch 88/120\n",
            "10000/10000 [==============================] - 6s 552us/step - loss: 0.2547 - accuracy: 0.8910 - val_loss: 0.4170 - val_accuracy: 0.8240\n",
            "Epoch 89/120\n",
            "10000/10000 [==============================] - 6s 603us/step - loss: 0.2558 - accuracy: 0.8902 - val_loss: 0.4273 - val_accuracy: 0.8390\n",
            "Epoch 90/120\n",
            "10000/10000 [==============================] - 6s 637us/step - loss: 0.2522 - accuracy: 0.8933 - val_loss: 0.4414 - val_accuracy: 0.8400\n",
            "Epoch 91/120\n",
            "10000/10000 [==============================] - 6s 582us/step - loss: 0.2491 - accuracy: 0.8944 - val_loss: 0.4459 - val_accuracy: 0.8300\n",
            "Epoch 92/120\n",
            "10000/10000 [==============================] - 6s 580us/step - loss: 0.2490 - accuracy: 0.8938 - val_loss: 0.4497 - val_accuracy: 0.8370\n",
            "Epoch 93/120\n",
            "10000/10000 [==============================] - 6s 596us/step - loss: 0.2437 - accuracy: 0.8950 - val_loss: 0.4434 - val_accuracy: 0.8310\n",
            "Epoch 94/120\n",
            "10000/10000 [==============================] - 6s 637us/step - loss: 0.2474 - accuracy: 0.8941 - val_loss: 0.4292 - val_accuracy: 0.8290\n",
            "Epoch 95/120\n",
            "10000/10000 [==============================] - 6s 599us/step - loss: 0.2491 - accuracy: 0.8936 - val_loss: 0.4359 - val_accuracy: 0.8230\n",
            "Epoch 96/120\n",
            "10000/10000 [==============================] - 6s 593us/step - loss: 0.2414 - accuracy: 0.8996 - val_loss: 0.4440 - val_accuracy: 0.8400\n",
            "Epoch 97/120\n",
            "10000/10000 [==============================] - 6s 590us/step - loss: 0.2443 - accuracy: 0.8962 - val_loss: 0.4184 - val_accuracy: 0.8410\n",
            "Epoch 98/120\n",
            "10000/10000 [==============================] - 6s 601us/step - loss: 0.2478 - accuracy: 0.8965 - val_loss: 0.4336 - val_accuracy: 0.8300\n",
            "Epoch 99/120\n",
            "10000/10000 [==============================] - 6s 616us/step - loss: 0.2365 - accuracy: 0.8981 - val_loss: 0.4212 - val_accuracy: 0.8280\n",
            "Epoch 100/120\n",
            "10000/10000 [==============================] - 6s 571us/step - loss: 0.2410 - accuracy: 0.9007 - val_loss: 0.4532 - val_accuracy: 0.8290\n",
            "Epoch 101/120\n",
            "10000/10000 [==============================] - 6s 581us/step - loss: 0.2390 - accuracy: 0.8988 - val_loss: 0.4517 - val_accuracy: 0.8390\n",
            "Epoch 102/120\n",
            "10000/10000 [==============================] - 6s 571us/step - loss: 0.2366 - accuracy: 0.8991 - val_loss: 0.4418 - val_accuracy: 0.8260\n",
            "Epoch 103/120\n",
            "10000/10000 [==============================] - 6s 573us/step - loss: 0.2331 - accuracy: 0.9016 - val_loss: 0.4343 - val_accuracy: 0.8170\n",
            "Epoch 104/120\n",
            "10000/10000 [==============================] - 6s 604us/step - loss: 0.2347 - accuracy: 0.9024 - val_loss: 0.4620 - val_accuracy: 0.8390\n",
            "Epoch 105/120\n",
            "10000/10000 [==============================] - 6s 588us/step - loss: 0.2307 - accuracy: 0.9026 - val_loss: 0.4449 - val_accuracy: 0.8310\n",
            "Epoch 106/120\n",
            "10000/10000 [==============================] - 6s 600us/step - loss: 0.2213 - accuracy: 0.9046 - val_loss: 0.4553 - val_accuracy: 0.8370\n",
            "Epoch 107/120\n",
            "10000/10000 [==============================] - 6s 604us/step - loss: 0.2296 - accuracy: 0.9021 - val_loss: 0.4626 - val_accuracy: 0.8310\n",
            "Epoch 108/120\n",
            "10000/10000 [==============================] - 6s 614us/step - loss: 0.2282 - accuracy: 0.9065 - val_loss: 0.4694 - val_accuracy: 0.8260\n",
            "Epoch 109/120\n",
            "10000/10000 [==============================] - 6s 557us/step - loss: 0.2284 - accuracy: 0.9045 - val_loss: 0.4567 - val_accuracy: 0.8320\n",
            "Epoch 110/120\n",
            "10000/10000 [==============================] - 6s 562us/step - loss: 0.2231 - accuracy: 0.9054 - val_loss: 0.5040 - val_accuracy: 0.8380\n",
            "Epoch 111/120\n",
            "10000/10000 [==============================] - 6s 568us/step - loss: 0.2225 - accuracy: 0.9087 - val_loss: 0.4787 - val_accuracy: 0.8210\n",
            "Epoch 112/120\n",
            "10000/10000 [==============================] - 6s 593us/step - loss: 0.2221 - accuracy: 0.9074 - val_loss: 0.4892 - val_accuracy: 0.8290\n",
            "Epoch 113/120\n",
            "10000/10000 [==============================] - 6s 574us/step - loss: 0.2244 - accuracy: 0.9074 - val_loss: 0.4770 - val_accuracy: 0.8250\n",
            "Epoch 114/120\n",
            "10000/10000 [==============================] - 6s 588us/step - loss: 0.2235 - accuracy: 0.9073 - val_loss: 0.4885 - val_accuracy: 0.8250\n",
            "Epoch 115/120\n",
            "10000/10000 [==============================] - 6s 573us/step - loss: 0.2205 - accuracy: 0.9079 - val_loss: 0.4790 - val_accuracy: 0.8290\n",
            "Epoch 116/120\n",
            "10000/10000 [==============================] - 6s 575us/step - loss: 0.2220 - accuracy: 0.9063 - val_loss: 0.4765 - val_accuracy: 0.8260\n",
            "Epoch 117/120\n",
            "10000/10000 [==============================] - 5s 544us/step - loss: 0.2149 - accuracy: 0.9152 - val_loss: 0.4662 - val_accuracy: 0.8200\n",
            "Epoch 118/120\n",
            "10000/10000 [==============================] - 6s 585us/step - loss: 0.2153 - accuracy: 0.9121 - val_loss: 0.4923 - val_accuracy: 0.8250\n",
            "Epoch 119/120\n",
            "10000/10000 [==============================] - 5s 548us/step - loss: 0.2217 - accuracy: 0.9054 - val_loss: 0.5248 - val_accuracy: 0.8240\n",
            "Epoch 120/120\n",
            "10000/10000 [==============================] - 5s 548us/step - loss: 0.2148 - accuracy: 0.9105 - val_loss: 0.4881 - val_accuracy: 0.8150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je8OMsMzU2wH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "182d7426-59dc-44f5-bc40-f0f184404395"
      },
      "source": [
        "# Plotting the training\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jriX5ucbWSr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test data evaluation\n",
        "\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdS1shBqWkUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f3763a0f-629d-4afa-9f6a-e31f9fb808cf"
      },
      "source": [
        "story =' '.join(word for word in test_data[0][0])\n",
        "print(\"Story: \",story)\n",
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(\"Question: \",query)\n",
        "print(\"True Test Answer from Data is:\",test_data[0][2])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Story:  Mary got the milk there . John moved to the bedroom .\n",
            "Question:  Is John in the kitchen ?\n",
            "True Test Answer from Data is: no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FjqqudgWpL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "33510ba8-e2a6-452a-a964-31d9a155f66f"
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.99996257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij_xTNuXWsbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "58ab7122-f465-4e44-bab1-48a3e2b0d4f0"
      },
      "source": [
        "# Let's write our own story\n",
        "# Let's check the Vocabulary to choose correct words\n",
        "vocab"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96v3q04SW8Db",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "61833386-9945-417d-8ffa-98cec7af6105"
      },
      "source": [
        "# Note the whitespace of the periods as I told you before.\n",
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxBlEZeTXF06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note that period is considered as seperate token as in training set. This is the reason for that space."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ca4ahOEXN7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_question = \"Is the football in the garden ?\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3LMMtJLXNy8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f7c7c9e-a400-4d66-bae9-9f8b61187f5e"
      },
      "source": [
        "my_question.split()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYOT11ePXSDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same logic for this question mark too."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3b_uUcRXW_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO-X-3-6Xaik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9XswDZZXcgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zCyUxbCXeRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9a9f55df-c61e-428c-cf20-49f79cf30d1f"
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.9224698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaA5RqBFX-h6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Thanks for reading my article. Have a great day."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJQOTU5HYIJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}